#!/usr/bin/env node

const fs = require('fs').promises;
const path = require('path');
const { Pool } = require('pg');

class DockerMigrationRunner {
  constructor() {
    this.pool = new Pool({
      connectionString: process.env.DATABASE_URL || 'postgresql://autollama:autollama@postgres:5432/autollama'
    });
    this.migrationsDir = path.join(__dirname, 'migrations');
    this.isDockerMode = process.argv.includes('--docker');
  }

  async run() {
    console.log('üê≥ Docker Migration Runner Starting...');
    
    try {
      // Wait for PostgreSQL in Docker environment
      if (this.isDockerMode) {
        await this.waitForPostgreSQL();
      }
      
      // Test database connection
      await this.testConnection();
      
      // Create migrations tracking table if not exists
      await this.createMigrationsTable();
      
      // Run all SQL migrations
      await this.runSqlMigrations();
      
      // Run the existing migration runner for any additional fixes
      await this.runExistingMigrations();
      
      // Add critical missing columns that are required for v2.3
      await this.addCriticalColumns();
      
      // Enable required extensions
      await this.enableExtensions();
      
      // Apply critical code fixes
      await this.applyCodeFixes();
      
      console.log('‚úÖ All migrations complete!');
      process.exit(0);
      
    } catch (error) {
      console.error('‚ùå Migration failed:', error);
      process.exit(1);
    }
  }

  async waitForPostgreSQL() {
    console.log('‚è≥ Waiting for PostgreSQL to be ready...');
    const maxRetries = 30;
    let retries = 0;
    
    while (retries < maxRetries) {
      try {
        await this.pool.query('SELECT 1');
        console.log('‚úÖ PostgreSQL is ready!');
        return;
      } catch (error) {
        retries++;
        console.log(`PostgreSQL is unavailable - attempt ${retries}/${maxRetries}`);
        await new Promise(resolve => setTimeout(resolve, 2000));
      }
    }
    
    throw new Error('PostgreSQL did not become ready within timeout period');
  }

  async testConnection() {
    try {
      await this.pool.query('SELECT NOW()');
      console.log('‚úÖ Database connection successful');
    } catch (error) {
      console.error('‚ùå Database connection failed:', error.message);
      throw error;
    }
  }

  async createMigrationsTable() {
    const query = `
      CREATE TABLE IF NOT EXISTS schema_migrations (
        version VARCHAR(255) PRIMARY KEY,
        name VARCHAR(255),
        executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        execution_time_ms INTEGER,
        checksum VARCHAR(64)
      );
    `;
    await this.pool.query(query);
    console.log('‚úÖ Migration tracking table ready');
  }

  async runSqlMigrations() {
    try {
      const files = await fs.readdir(this.migrationsDir);
      const sqlFiles = files
        .filter(f => f.endsWith('.sql'))
        .sort();
      
      console.log(`üìÅ Found ${sqlFiles.length} SQL migration files`);
      
      for (const file of sqlFiles) {
        const migrationPath = path.join(this.migrationsDir, file);
        const version = file.split('_')[0] || file.replace('.sql', '');
        
        const isApplied = await this.isMigrationApplied(version);
        
        if (!isApplied) {
          console.log(`üìù Running migration: ${file}`);
          await this.runSqlMigration(migrationPath, file, version);
          console.log(`‚úÖ Migration completed: ${file}`);
        } else {
          console.log(`‚è≠Ô∏è  Skipping applied migration: ${file}`);
        }
      }
    } catch (error) {
      console.log('‚ÑπÔ∏è No migrations directory found or accessible');
    }
  }

  async isMigrationApplied(version) {
    try {
      const result = await this.pool.query(
        'SELECT 1 FROM schema_migrations WHERE version = $1',
        [version]
      );
      return result.rows.length > 0;
    } catch (error) {
      // If the table doesn't exist, migration is not applied
      return false;
    }
  }

  async runSqlMigration(migrationPath, fileName, version) {
    const startTime = Date.now();
    const client = await this.pool.connect();
    
    try {
      await client.query('BEGIN');
      
      // Read and execute migration
      const content = await fs.readFile(migrationPath, 'utf8');
      await client.query(content);
      
      // Record migration
      await client.query(
        `INSERT INTO schema_migrations (version, name, execution_time_ms) 
         VALUES ($1, $2, $3)
         ON CONFLICT (version) DO NOTHING`,
        [version, fileName, Date.now() - startTime]
      );
      
      await client.query('COMMIT');
      
    } catch (error) {
      await client.query('ROLLBACK');
      
      // Some errors are acceptable (already exists, etc.)
      if (error.message.includes('already exists') || 
          error.message.includes('duplicate column') ||
          error.message.includes('does not exist')) {
        console.log(`‚ÑπÔ∏è Migration already applied or not needed: ${fileName}`);
        
        // Still record it as applied
        try {
          await client.query('BEGIN');
          await client.query(
            `INSERT INTO schema_migrations (version, name, execution_time_ms) 
             VALUES ($1, $2, $3)
             ON CONFLICT (version) DO NOTHING`,
            [version, fileName, 0]
          );
          await client.query('COMMIT');
        } catch (recordError) {
          await client.query('ROLLBACK');
        }
      } else {
        throw error;
      }
    } finally {
      client.release();
    }
  }

  async runExistingMigrations() {
    try {
      console.log('üîÑ Running existing migration system...');
      const MigrationRunner = require('./run-migrations.js');
      const runner = new MigrationRunner();
      
      const needed = await runner.checkMigrationsNeeded();
      if (needed) {
        await runner.runMigrations();
        console.log('‚úÖ Existing migrations completed');
      } else {
        console.log('‚úÖ No additional migrations needed');
      }
      
      await runner.close();
      
    } catch (error) {
      console.log('‚ÑπÔ∏è Existing migration system completed with minor issues:', error.message);
    }
  }

  async addCriticalColumns() {
    console.log('üîß Adding critical v2.3 columns...');
    
    const criticalColumns = [
      // From fix-schema.sh analysis
      'ALTER TABLE processed_content ADD COLUMN IF NOT EXISTS upload_source VARCHAR(50) DEFAULT \'user\'',
      'ALTER TABLE processed_content ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP',
      'ALTER TABLE processed_content ADD COLUMN IF NOT EXISTS record_type VARCHAR(20) DEFAULT \'chunk\'',
      'ALTER TABLE processed_content ADD COLUMN IF NOT EXISTS parent_document_id INTEGER',
      
      // Add missing indexes
      'CREATE INDEX IF NOT EXISTS idx_processed_content_upload_source ON processed_content(upload_source)',
      'CREATE INDEX IF NOT EXISTS idx_processed_content_updated_at ON processed_content(updated_at DESC)',
      'CREATE INDEX IF NOT EXISTS idx_processed_content_parent_document_id ON processed_content(parent_document_id)',
      'CREATE INDEX IF NOT EXISTS idx_processed_content_record_type ON processed_content(record_type)'
    ];

    for (const sql of criticalColumns) {
      try {
        await this.pool.query(sql);
        console.log('‚úÖ Applied:', sql.substring(0, 60) + '...');
      } catch (error) {
        if (error.message.includes('already exists') || error.message.includes('duplicate')) {
          console.log('‚ÑπÔ∏è Already exists:', sql.substring(0, 60) + '...');
        } else {
          console.error('‚ùå Failed:', error.message);
        }
      }
    }
  }

  async enableExtensions() {
    console.log('üîå Enabling required PostgreSQL extensions...');
    
    const extensions = [
      'CREATE EXTENSION IF NOT EXISTS "uuid-ossp"',
      'CREATE EXTENSION IF NOT EXISTS "vector"',
      'CREATE EXTENSION IF NOT EXISTS "pg_trgm"'
    ];

    for (const sql of extensions) {
      try {
        await this.pool.query(sql);
        console.log('‚úÖ Extension enabled:', sql);
      } catch (error) {
        if (error.message.includes('already exists')) {
          console.log('‚ÑπÔ∏è Extension already enabled:', sql);
        } else {
          console.log('‚ö†Ô∏è Extension not available (non-critical):', error.message);
        }
      }
    }
  }

  async applyCodeFixes() {
    console.log('üîß Applying critical code fixes...');
    
    try {
      // Check if analyzeChunk fix is needed in server.js
      const serverJsPath = path.join(__dirname, 'server.js');
      const serverContent = await fs.readFile(serverJsPath, 'utf8');
      
      // Check if the problematic line exists
      if (serverContent.includes('analyzeChunk(chunk.chunk_text)') && 
          !serverContent.includes('services.analysisService.analyzeChunk(chunk.chunk_text)')) {
        
        console.log('‚ö†Ô∏è Found analyzeChunk function call issue in server.js');
        console.log('‚úÖ This should be fixed by building the container with the updated code');
        console.log('   The fix replaces analyzeChunk() with services.analysisService.analyzeChunk()');
        
      } else if (serverContent.includes('services.analysisService.analyzeChunk(chunk.chunk_text)')) {
        console.log('‚úÖ analyzeChunk function fix already applied');
      } else {
        console.log('‚ÑπÔ∏è No analyzeChunk pattern found (may be using different code version)');
      }
      
    } catch (error) {
      console.log('‚ÑπÔ∏è Code fix check completed with minor issues:', error.message);
    }
  }

  async close() {
    await this.pool.end();
  }
}

// Run if called directly
if (require.main === module) {
  const runner = new DockerMigrationRunner();
  runner.run().catch(error => {
    console.error('Migration runner failed:', error);
    process.exit(1);
  });
}

module.exports = DockerMigrationRunner;