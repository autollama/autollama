{
  "name": "autollama",
  "version": "2.3.4",
  "description": "Production-ready RAG platform with embedded databases, contextual embeddings, and one-command deployment",
  "keywords": [
    "rag",
    "llm",
    "embeddings",
    "vector-search", 
    "openai",
    "document-processing",
    "semantic-search",
    "ai",
    "contextual-embeddings",
    "qdrant",
    "postgresql",
    "docker",
    "production-ready"
  ],
  "homepage": "https://github.com/snedea/autollama#readme",
  "repository": {
    "type": "git",
    "url": "https://github.com/snedea/autollama.git"
  },
  "bugs": {
    "url": "https://github.com/snedea/autollama/issues"
  },
  "license": "MIT",
  "author": {
    "name": "AutoLlama Contributors",
    "url": "https://github.com/snedea/autollama/contributors"
  },
  "engines": {
    "node": ">=16.0.0",
    "docker": ">=20.0.0"
  },
  "scripts": {
    "start": "docker compose -f docker-compose.public.yaml up -d",
    "stop": "docker compose -f docker-compose.public.yaml down",
    "logs": "docker compose -f docker-compose.public.yaml logs -f",
    "health": "curl -f http://localhost:7734/health"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.57.0",
    "dotenv": "^17.2.1",
    "pg": "^8.16.3"
  }
}
