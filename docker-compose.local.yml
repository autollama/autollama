# AutoLlama v2.3.4 - Pure Local Mode for Enterprise/Air-Gapped Deployments
# Complete local stack with ZERO external dependencies
# Optimized for enterprise hardware: 2x Xeon, 64GB RAM, 2x RTX 3060
# 
# Quick Start:
#   cp .env.local.example .env.local
#   docker-compose -f docker-compose.local.yml up -d
#   Access: http://localhost:8080

version: '3.8'

services:
  # React Frontend - Local Mode
  autollama-frontend:
    build: 
      context: ./config/react-frontend
      dockerfile: Dockerfile
    ports:
      - "8080:80"
    environment:
      - NODE_ENV=production
      - REACT_APP_API_URL=http://localhost:3001
      - REACT_APP_MODE=local
    depends_on:
      autollama-api:
        condition: service_healthy
      autollama-bm25:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - autollama-local
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # API Server - Air-Gapped Configuration
  autollama-api:
    build: ./api
    ports:
      - "3001:3001"
      - "3003:3003"
    environment:
      # Core Configuration
      - NODE_ENV=production
      - PORT=3001
      - WS_PORT=3003
      
      # LOCAL MODE: Air-gapped isolation
      - VECTOR_DB_MODE=local
      - VECTOR_DB_MODE_LOCKED=${VECTOR_DB_MODE_LOCKED:-false}
      
      # Local Services Only
      - DATABASE_URL=postgresql://autollama:autollama_secure_password@postgres-local:5432/autollama
      - QDRANT_LOCAL_URL=http://qdrant-local:6333
      - REDIS_URL=redis://redis-local:6379
      
      # AI Configuration (Only external dependency if needed)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ENABLE_CONTEXTUAL_EMBEDDINGS=${ENABLE_CONTEXTUAL_EMBEDDINGS:-true}
      - CONTEXTUAL_EMBEDDING_MODEL=${CONTEXTUAL_EMBEDDING_MODEL:-gpt-4o-mini}
      
      # Security & Isolation
      - DEPLOYMENT_MODE=local
      - TELEMETRY_DISABLED=true
      - ANALYTICS_DISABLED=true
      - DEBUG_MODE=${DEBUG_MODE:-false}
      
      # Network Configuration
      - FRONTEND_URL=http://localhost:8080
      - ALLOWED_ORIGINS=http://localhost:8080,http://127.0.0.1:8080
      
      # Enterprise Configuration
      - MAX_FILE_SIZE=100MB
      - CHUNK_SIZE_MIN=100
      - CHUNK_SIZE_MAX=5000
      - CHUNK_OVERLAP_DEFAULT=200
      
    volumes:
      - ./api/uploads:/app/uploads
      - ./logs/api:/app/logs
      - ./data/exports:/app/exports
    restart: unless-stopped
    depends_on:
      postgres-local:
        condition: service_healthy
      qdrant-local:
        condition: service_healthy
      redis-local:
        condition: service_healthy
    networks:
      - autollama-local
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # BM25 Search Service - Local Only
  autollama-bm25:
    build: ./bm25-service
    ports:
      - "3002:3002"
    environment:
      - PORT=3002
      - PYTHONPATH=/app
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - DEPLOYMENT_MODE=local
    volumes:
      - autollama-bm25-data:/app/data/bm25_indices
      - ./logs/bm25:/app/logs
    restart: unless-stopped
    networks:
      - autollama-local
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:3002/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

  # Local PostgreSQL Database - Enterprise Optimized
  postgres-local:
    image: postgres:15.4-alpine  # Pinned version for enterprise stability
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=autollama
      - POSTGRES_USER=autollama
      - POSTGRES_PASSWORD=autollama_secure_password
      - POSTGRES_INITDB_ARGS=--auth-host=md5 --encoding=UTF8 --locale=C
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres-local-data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d:ro
      - ./logs/postgres:/var/log/postgresql
      - ./config/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    restart: unless-stopped
    networks:
      - autollama-local
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U autollama -d autollama"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8.0'
        reservations:
          memory: 8G
          cpus: '4.0'
    # Enterprise PostgreSQL Configuration for 64GB RAM system
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c shared_buffers=4GB
      -c effective_cache_size=12GB
      -c maintenance_work_mem=1GB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=32MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=64MB
      -c max_connections=200
      -c shared_preload_libraries=pg_stat_statements
      -c logging_collector=on
      -c log_directory=/var/log/postgresql
      -c log_filename=postgresql-%Y-%m-%d.log
      -c log_min_duration_statement=1000
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Local Qdrant Vector Database - Air-Gapped Configuration
  qdrant-local:
    image: qdrant/qdrant:v1.6.1  # Pinned version for enterprise stability
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-local-data:/qdrant/storage
      - ./config/qdrant:/qdrant/config:ro
      - ./logs/qdrant:/qdrant/logs
    environment:
      # Core Configuration
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__LOG_LEVEL=INFO
      
      # Enterprise Performance Tuning
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS=8
      - QDRANT__STORAGE__PERFORMANCE__MAX_OPTIMIZATION_THREADS=4
      - QDRANT__STORAGE__QUANTIZATION__SCALAR__ALWAYS_RAM=true
      
      # Air-Gapped Security
      - QDRANT__TELEMETRY_DISABLED=true
      - QDRANT__CLUSTER__ENABLED=false
      
      # Memory Management for 64GB System
      - QDRANT__STORAGE__MEMORY_THRESHOLD=8589934592  # 8GB
      - QDRANT__STORAGE__OPTIMIZERS_CONFIG__MAX_SEGMENT_SIZE=20971520  # 20MB
      
    restart: unless-stopped
    networks:
      - autollama-local
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8.0'
        reservations:
          memory: 8G
          cpus: '4.0'
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Redis Cache - Local Performance Optimization
  redis-local:
    image: redis:7.2.3-alpine  # Pinned version for enterprise stability
    ports:
      - "6379:6379"
    command: >
      redis-server
      --maxmemory 4gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
      --tcp-keepalive 60
      --timeout 0
    volumes:
      - redis-local-data:/data
      - ./logs/redis:/var/log/redis
    restart: unless-stopped
    networks:
      - autollama-local
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 5G
          cpus: '2.0'
        reservations:
          memory: 4G
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

# Persistent Volumes for Local Data with Host Binding
volumes:
  postgres-local-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/postgres-local
  qdrant-local-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/qdrant-local
  autollama-bm25-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/bm25-local
  redis-local-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/redis-local

# Isolated Local Network for Air-Gapped Security
networks:
  autollama-local:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/24
          gateway: 172.30.0.1
    driver_opts:
      com.docker.network.bridge.name: autollama-local
      com.docker.network.bridge.enable_ip_masquerade: "false"